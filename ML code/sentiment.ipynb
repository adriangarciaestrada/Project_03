{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1596497441560",
   "display_name": "Python 3.6.10 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                    text  label\n0      Easily the worst movie I have ever seen in my ...      0\n1      Ambushed is no ordinary action flick Its much ...      0\n2      I loved this movie but then again I am a big C...      1\n3      In 1933 Dick Powell and Ruby Keeler sang and d...      1\n4      To make any film about the supposed end of the...      0\n...                                                  ...    ...\n49995  While its true that the movie is somewhat inte...      0\n49996  From the upper shelf of great Classic Books co...      1\n49997  Good ideashame about the actual movie Would of...      0\n49998  An unusual film for an audience outside the US...      1\n49999  I really enjoyed The 60s Not being of that gen...      1\n\n[50000 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Easily the worst movie I have ever seen in my ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ambushed is no ordinary action flick Its much ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I loved this movie but then again I am a big C...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>In 1933 Dick Powell and Ruby Keeler sang and d...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>To make any film about the supposed end of the...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>49995</th>\n      <td>While its true that the movie is somewhat inte...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49996</th>\n      <td>From the upper shelf of great Classic Books co...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49997</th>\n      <td>Good ideashame about the actual movie Would of...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49998</th>\n      <td>An unusual film for an audience outside the US...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>49999</th>\n      <td>I really enjoyed The 60s Not being of that gen...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>50000 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from os import system, listdir\n",
    "from random import shuffle\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "directory = './aclImdb/train/neg'\n",
    "neg = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "        f = open(f'{directory}/{filename}', encoding='utf-8')\n",
    "        lines = f.read()\n",
    "        neg.append(lines)\n",
    "\n",
    "directory = './aclImdb/test/pos'\n",
    "pos = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "        f = open(f'{directory}/{filename}', encoding='utf-8')\n",
    "        lines = f.read()\n",
    "        pos.append(lines)\n",
    "\n",
    "directory = './aclImdb/test/neg'\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "        f = open(f'{directory}/{filename}', encoding='utf-8')\n",
    "        lines = f.read()\n",
    "        neg.append(lines)\n",
    "\n",
    "directory = './aclImdb/train/pos'\n",
    "for filename in os.listdir(directory):\n",
    "        f = open(f'{directory}/{filename}', encoding='utf-8')\n",
    "        lines = f.read()\n",
    "        pos.append(lines)\n",
    "\n",
    "\n",
    "negative = pd.DataFrame(neg)\n",
    "negative[\"label\"] = 0\n",
    "positive = pd.DataFrame(pos)\n",
    "positive[\"label\"] = 1\n",
    "all = pd.concat([negative, positive])\n",
    "all.fillna(0, inplace=True)\n",
    "all = all.rename(columns={0: \"text\"}).reset_index(drop=True)\n",
    "import string\n",
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "all['text'] = all['text'].apply(remove_punctuations)\n",
    "all = all.sample(frac=1).reset_index(drop=True)\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 1), stop_words='english')\n",
    "vectorizer.fit(all['text'].values)\n",
    "vectorized = vectorizer.transform(all['text'].values)\n",
    "\n",
    "idf_transformer = TfidfTransformer()\n",
    "idf_transformer.fit(vectorized)\n",
    "listofwords = vectorizer.get_feature_names()\n",
    "transformed = idf_transformer.transform(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.9317866666666667 0.89104\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    0  1\n0   0  0\n1   1  1\n2   0  0\n3   0  0\n4   0  0\n5   1  1\n6   1  1\n7   1  1\n8   0  0\n9   1  1\n10  0  0\n11  0  0\n12  0  0\n13  0  0\n14  0  0\n15  1  1\n16  1  1\n17  0  0\n18  1  1\n19  1  1\n20  0  0\n21  0  0\n22  0  0\n23  1  1\n24  0  0\n25  1  1\n26  1  0\n27  1  1\n28  0  0\n29  1  1\n30  0  0\n31  1  1\n32  0  0\n33  1  1\n34  1  1\n35  1  1\n36  0  0\n37  0  0\n38  1  1\n39  0  0\n40  0  0\n41  1  1\n42  1  1\n43  1  1\n44  0  0\n45  1  1\n46  0  0\n47  0  0\n48  1  0\n49  0  0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "y = all['label'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed, y)\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "train_score = clf.score(X_train, y_train)\n",
    "test_score = clf.score(X_test, y_test)\n",
    "prediction = clf.predict(X_test)\n",
    "print(train_score, test_score)\n",
    "comparison = zip(prediction,y_test)\n",
    "comp_df = pd.DataFrame(comparison)\n",
    "comp_df.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(0, 177219)\t0.06064867073112247\n  (0, 174654)\t0.06390620706490707\n  (0, 173659)\t0.0553182571226014\n  (0, 172764)\t0.05775006811500919\n  (0, 172179)\t0.044483670624848586\n  (0, 172029)\t0.209049560644247\n  (0, 171338)\t0.05036885740117296\n  (0, 169112)\t0.03793172130657826\n  (0, 167597)\t0.05459352318901869\n  (0, 167376)\t0.0816202647008793\n  (0, 167040)\t0.06127155259994756\n  (0, 165728)\t0.08013898949201938\n  (0, 165451)\t0.04328751771265208\n  (0, 161062)\t0.046142664352445226\n  (0, 160241)\t0.06185957705541855\n  (0, 159629)\t0.08633301754103288\n  (0, 159217)\t0.2074265251465489\n  (0, 156768)\t0.03741527520278621\n  (0, 155603)\t0.0736086138957696\n  (0, 155600)\t0.11327230129865778\n  (0, 152753)\t0.053359992797391904\n  (0, 151321)\t0.07485982592846223\n  (0, 151238)\t0.03681853451533682\n  (0, 151155)\t0.03454056313425026\n  (0, 150029)\t0.055875360711961704\n  :\t:\n  (37499, 161178)\t0.06642144562169844\n  (37499, 131423)\t0.15980535791884432\n  (37499, 122111)\t0.054180008834800425\n  (37499, 121829)\t0.0713667769120991\n  (37499, 118130)\t0.11270557183818028\n  (37499, 114393)\t0.22963891589950872\n  (37499, 106867)\t0.06904861857302026\n  (37499, 105377)\t0.06189796515039913\n  (37499, 94542)\t0.28115128558982166\n  (37499, 92472)\t0.03658656706661781\n  (37499, 82506)\t0.12236425759121247\n  (37499, 81902)\t0.20885473061576504\n  (37499, 74907)\t0.0858631363588149\n  (37499, 59823)\t0.3609956676329832\n  (37499, 44616)\t0.08243292660603874\n  (37499, 39995)\t0.1064432826101222\n  (37499, 34483)\t0.10290644833116401\n  (37499, 31604)\t0.0781824518984274\n  (37499, 31051)\t0.08447926028893188\n  (37499, 26930)\t0.30479647647227964\n  (37499, 22237)\t0.2201877284176845\n  (37499, 13573)\t0.12666208123749076\n  (37499, 10599)\t0.18265300183348737\n  (37499, 5411)\t0.09449010124199185\n  (37499, 4633)\t0.13071784141092768\n"
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_comment = \"\"\"In all my series and movie watching years I have never seen a serie so well thought through as this. Don't let the language barrier stop you from watching this. Acting and character building are superb. Hint: grab a pen and some paper and keep track ;) Also there is totally no comparison to Stranger Things (and I have seen all 3 seasons) This is in a league of it's own entirely. Well done! Netflix more of this please!!!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame([new_comment])\n",
    "new_df[0] = new_df[0].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text\n0  In all my series and movie watching years I ha...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>In all my series and movie watching years I ha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "new_df = new_df.rename(columns={0:\"text\"})\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_unigram = vectorizer.transform(new_df[\"text\"].values)\n",
    "\n",
    "X_train_unigram_tf_idf = idf_transformer.transform(X_train_unigram)\n",
    "\n",
    "new_prediction = clf.predict(X_train_unigram_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Positive\n"
    }
   ],
   "source": [
    "if new_prediction[0] == 1:\n",
    "    text_prediction = \"Positive\"\n",
    "else:\n",
    "    text_prediction = \"Negative\"\n",
    "print(text_prediction)"
   ]
  }
 ]
}